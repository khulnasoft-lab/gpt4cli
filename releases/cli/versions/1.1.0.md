## Support for loading images into context with gpt-4o üñºÔ∏è

- You can now load images into context with `gpt4cli load path/to/image.png`. Supported image formats are png, jpeg, non-animated gif, and webp. So far, this feature is only available with the default OpenAI GPT-4o model.

![gpt4cli-load-images](https://github.com/khulnasoft/gpt4cli/blob/main/releases/images/cli/1.1.0/gpt4cli-images.gif)

## No more hard OpenAI requirement for builder, verifier, and auto-fix roles üß†

- Non-OpenAI models can now be used for *all* roles, including the builder, verifier, and auto-fix roles, since streaming function calls are no longer required for these roles.

- Note that reliable function calling is still required for these roles. In testing, it was difficult to find models that worked reliably enough for these roles, despite claimed support for function calling. For this reason, using non-OpenAI models for these roles should be considered experimental. Still, this provides a path forward for using open source, local, and other non-OpenAI models for these roles in the future as they improve.

## Reject pending changes with `gpt4cli reject` üö´

- You can now reject pending changes to one or more files with the `gpt4cli reject` command. Running it with no arguments will reject all pending changes after confirmation. You can also reject changes to specific files by passing one or more file paths as arguments.

![gpt4cli-reject](https://github.com/khulnasoft/gpt4cli/blob/main/releases/images/cli/1.1.0/gpt4cli-reject.gif)

## Summarization and auto-continue fixes üõ§ Ô∏è

- Fixes for summarization and auto-continue issues that could Gpt4cli to lose track of where it is in the plan and repeat tasks or do tasks out of order, especially when using `tell` and `continue` after the initial `tell`.

## Verification and auto-fix improvements üõ†Ô∏è

- Improvements to the verification and auto-fix step. Gpt4cli is now more likely to catch and fix placeholder references like "// ... existing code ..." as well as incorrect removal or overwriting of code.

## Stale context fixes üîÑ

- After a context file is updated, Gpt4cli is less likely to use an old version of the code from earlier in the conversation--it now uses the latest version much more reliably.

## `gpt4cli convo` command improvements üó£Ô∏è

- Added a `--plain / -p` flag to `gpt4cli convo` and `gpt4cli summary` that outputs the conversation/summary in plain text with no ANSI codes.
- `gpt4cli convo` now accepts a message number or range of messages to display (e.g. `gpt4cli convo 1`, `gpt4cli convo 1-5`, `gpt4cli convo 2-`). Use `gpt4cli convo 1` to show the initial prompt.

## Context management improvements üìÑ

- Give notes added to context with `gpt4cli load -n 'some note'` an auto-generated name in the `context ls` list.
- `gpt4cli rm` can now accept a range of indices to remove (e.g. `gpt4cli rm 1-5`)
- Better help text if `gpt4cli load` is run with incorrect arguments
- Fix for `gpt4cli load` issue loading paths that begin with `./`

## Better rate limit tolerance üï∞Ô∏è

- Increase wait times when receiving rate limit errors from OpenAI API (common with new OpenAI accounts that haven't spent $50)

## Built-in model updates üß†

- Removed 'gpt-4-turbo-preview' from list of built-in models and model packs

## Other fixes üêû

- Fixes for some occasional rendering issues when streaming plans and build counts
- Fix for `gpt4cli set-model` model selection showing built-in model options that aren't compatible with the selected role--now only compatible models are shown

## Help updates üìö

- `gpt4cli help` now shows a brief overview on getting started with Gpt4cli rather than the full command list
- `gpt4cli help --all` or `gpt4cli help -a` shows the full command list